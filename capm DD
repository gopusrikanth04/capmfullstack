    "cds": {
        "requires": {
            "db": {
                "kind": "hana"
            }
        }
    }


    


Sass : 
npm i -g generator-saphanaacademy-saas


CAP M Procedure:
-----------
Procedure 1:
=============
  
  How to create a capm steps for end processes:
----------------------------------------------
1. create a dev space 
   what kind of application do u want to create: full stack cloud application
   select the additional sapextensions:
       sap hana calculation view editor
	   create the dev space

2. Login in cloud foundry
3. create a smple capm project 
     Enter your project name: MyHANAApp
	 Select your runtime: Nodejs
	 Add features to your project: 
	    Select these checkboxs
			CI/CD Pipeline Integration
			Configuration for SAP HANA Deployment
			MTA Based SAP BTP Deploy
4. [npm install]
5. write the schema, data and services and handlers etc..	
 
6. when you tried to run using cds watch command you get this error: No database credentials provided
7. In MTA File contains different modules and resources:
 modules
    1. name: MyHANAApp-srv (Service Module of type Nodejs)
    2. name: MyHANAApp-db-deployer (Database Module)
	   requires: 
	     - name: MyHANAApp-db (Depends on HDI Container)
 resources:
    name: MyHANAApp-db (HDI Container)
	
8. NOTE: if your mta.yaml doesn’t look like in the previous step (it is missing the HANA DB module and resources), 
         this could be a current bug in the wizard
   From the terminal the command [cds add hana]. This should correct your mta.yaml.
9.The Cloud Application Programming Model wizard generates a project that supports HANA development but is not fully configured 
   to target HANA during the development phase. 
   In this step we will adjust the generated project to fully compatible to also contain HANA native artifacts as well.

  From the mta.yaml file we were just looking at the in the previous step, edit the path of the database module, adjusting the path from [gen/db] to just [db]
  
  name: MyHANAApp-db-deployer
  type: hdb
  path:db #gen/db
  parameters:
    buildpack: nodejs_buildpack
  requires:
   - name: MyHANAApp-db
   
10. The rest of the changes will be in the cds section of the file. Replace this entire section of package.json with the following content

       "cds": {
    "build": {
        "tasks": [
            {
                "for": "hana",
                "dest": "../db"
            },
            {
                "for": "node-cf"
            }
        ]
    },
    "requires": {
        "db": {
            "kind": "hana-cloud"
        }
    }
}

These changes will alter the generated folder structure of the cds build operation. 
Content will no longer be placed into the gen folder for the db module but back into the 
source folders. This also will tell CAP to generate hdbtable artifacts instead of hdbcds. 
This is a critical change for SAP HANA Cloud compatibility. Finally the db.kind change to 
HANA tells CAP to use HANA Cloud at development time instead of SQLite.

		 
11. For one last change we need to adjust the content generated by the wizard for the db folder. 
The CAP wizard expects that you will use the cds deploy command to send content into HANA. 
However to use the HANA Projects view to deploy to HANA we need some additional files in the db folder. 
Mainly we need a package.json file that will run the [@sap-hdi-deploy] module. 
Rather than create this file manually, we will use an open source sample utility called [hana-cli]. 
From this same terminal window run the command [npm install -g hana-cli]
  {npm install -g hana-cli}
  
  After installation run the command [hana-cli createModule]
  
  
 =====================================================================================================
 
 Procedure 2:
 ============
     
     Create Database Artifacts Using Core Data Services (CDS) for SAP HANA Cloud
---------------------------------------------------------------------------
12. [cds build] it generates  design-time artifacts 
     If you pay attention to the build log in the console, you will see the CDS artifacts were converted to hdbtable
	 and hdbview 
	 artifacts. You will find those artifacts in a new folder under src called ge in db folder
	 
	 
13. You will now deploy those objects into the HANA Database creating tables and views. We will use the SAP HANA Projects view to do 
    this. Please expand this view and you will see the following:
	 We need to bind our project to a Database Connection and HDI container instance. Press the bind icon to being the process.
	 
	 If you receive either of these two following warning dialogs, please just choose Continue (nothing will be deleted because we are create a new HDI Container Instance) and Enable 
	 (automatic undeploy is quite helpful during the development process for the reasons described in this dialog)
	 
14. Deploy the databases after success click on database explorer

Use SAP HANA Cloud and CAP to Build a Full-Stack Application:
-------------------------------------------------------------
15. In env file: in db folder VCAP_SERVICES={"hana":[{"name":"MyHanaApp-db","instance_name":"MyHanaApp-db",

  We can use this same configuration information from Cloud Foundry to start the CAP service layer and connect it to SAP HANA as well. 
   Use the command [cds bind -2 MyHanaApp-db:SharedDevKey] to tell CAP to bind to this same HANA Cloud HDI service instance that we 
   bound to earlier in the SAP HANA Projects view
   
16. npm install

17. cds watch --profile hybrid  // u can see all the end points

18. Configure routing:  You will now create an Application Router module. This module is very important as it will become the entry 
    point for your application. Every request coming to this module will be routed into the different backend services.
	by using command: [cds add approuter]
	it will generate three files in app folder
	  1. default-env.json
	  2. package.json
	  3. xs-app.json for app router
	  
	 and in main folder: xs-security.json file for xsuaa
	 
19. navigate to app folder and npm i 
20. Replace the content of xs-app.json with the following content
     {
"authenticationMethod": "none",
"routes": [
    {
    "source": "^/app/(.*)$",
    "target": "$1",
    "localDir": ".",
    "cacheControl": "no-cache, no-store, must-revalidate"
    },
    {
    "source": "^/(.*)$",
    "target": "$1",
    "destination": "srv-api",
    "csrfProtection": true
    }
]
}

21. Create a Fiori freestyle web interface: From the top menu select View -> Command Pallette. Then type fiori into the search box. 
     Select Fiori Open Application Generator. select the SAPUI5 freestyle and select the application type click next
	 
22. Select the data source as [use a local capm project]
    select cap project folder path and odata service and next
	
23. In Project Attributes 
      Add deployment configuration to MTA Project: No
	  Add FLP configuration: No
	  Configure advanced option: yes 
	  Add javascript code assist lib to your project: No
	  Skip generation of associated annotations.cds file: Yes
	  
24: [cds watch --profile hybrid] and click on index.html

25. If you wish you can open another terminal instance and change to the Application Router folder (cd app). Then run the command [npm start]. 
    This will run the Application Router which you can test from it’s own port (5000). Nothing will really look different at this point, 
	but you are passing all requests through the Application Router now. This will become important once we add security to our service and want 
	to test it locally using the Application Router.
	
26. When you do add scopes to the services as we did in the previous step you can generate a sample xs-security.json using the following 
    command and merge that into the basics xs-security.json file generated by the Application Router wizard.
	cmd: [cds compile srv/ --to xsuaa > xs-security.json]
	
27. add this code in xs-security.json objects
    "oauth2-configuration": {
    "credential-types": [
        "binding-secret",
        "x509"
    ],
    "redirect-uris": [
        "https://*.applicationstudio.cloud.sap/**"
    ]
   }
28. Open a terminal and create the XSUAA services instance with the xs-security.json configuration using the following command:
    cmd: [cf create-service xsuaa application MyHANAApp-auth -c xs-security.json]
	
29. Configure the application: 
    cmd1: [cf create-service-key MyHANAApp-auth default]
    cmd2: [cds bind -2 MyHANAApp-auth:default]
	
30. Create and grant roles for application
    The roles collections are created on subaccount level in the cockpit. Navigate to your subaccount and then to Security > Role Collections. 
	Then press the + to create a new Role Collection.
	
	Name your role collection MyHANAApp. Then go into edit mode on the role collection. Use the value help for the Role. Use the Application 
	Identifier to find your service instance (myhanaapp!XXXXX). Select the role and press Add
	
31. From the Role Collection edit screen you can also grant the role to your user. In the Users section fill in your email address you use for your 
    SAP BTP account. Save the Role Collection.

32. Adjust Application Router:
    The approuter component implements the necessary handshake with XSUAA to let the user log in interactively. The resulting JWT token is sent to the
	application where it’s used to enforce authorization.

    Next open the xs-app.json file in the /app folder. Here want to make several adjustments. Change the authenicationMethod to route. 
	This will turn on authentication. You can deactivate it later by switching back to none. Also add/update the routes. We are adding 
	authentication to CAP service route. We are also adding the Application Router User API route (sap-approuter-userapi), which is nice for testing
	the UAA connection. We will also add the custom logoutEndpoint of /app-logout. You can add this path to your URL if you want to force logout your
	user; which can be helpful to pickup any changes to your role configuration during development. Finally add the route to the local directory to
	serve the UI5/Fiori web content.
	
	{
"authenticationMethod": "route",
"logout": {
    "logoutEndpoint": "/app-logout",
    "logoutPage": "/"
},
"routes": [
    {
        "source": "^/app/(.*)$",
        "target": "$1",
        "localDir": ".",
        "cacheControl": "no-cache, no-store, must-revalidate",
        "authenticationType": "xsuaa"
    },
    {
        "source": "^/user-api(.*)",
        "target": "$1",
        "service": "sap-approuter-userapi"
    },
    {
        "source": "^/(.*)$",
        "target": "$1",
        "destination": "srv-api",
        "csrfProtection": true,
        "authenticationType": "xsuaa"
    }
]
}

33. cds bind --exec -- npm start --prefix app to open in 5000 port

34. if u get bad gate way error run the [cds watch --profile hybrid] command and if its require cf login login 


======================================================================
Procedure 3:
===========
Create Calculation View and Expose via CAP (SAP HANA Cloud)
===========================================================
34. Create a new Calculation View via View > Command Pallette and then SAP HANA: Create SAP HANA Database Artifact command pallet entry.

35. Create a calculation view called V_INTERACTION of Data Category DIMENSION and Dimension Type of STANDARD. Press Create

36.path:  /home/user/projects/MyHanaApp2/db/src/
   Choose the database version: HANA Cloud
   artifact type: calculation view
   artifact name: V_INTERACTION
   data cateogery: dimension
   categrory type: standard
   
   The new artifact is created in the /db/src folder alongside the /gen content created by CAP. This way you can have a single HANA database
   model that contains both HANA native content and CAP generated content
   
38. Click on the V_INTERACTION.hdbcalculationview to load the graphical calculation view editor
39. Drop a join node into the modeling space
40. Use the plus sign sign to add tables to the node AND tables
41. Double-click on the join node. A panel will open on the right.
42. Set the cardinality to 1..n by using drag
43. Connect the join node with the Projection node using the arrow

Create calculation view proxy entity:
------------------------------------
44. We need our proxy entity to be created without the namespace in our current interactions.cds. 
    Therefore comment out the namespace line and add all the existing content except the using ... line in a new context for app.interactions.
	
	in schema.cds: namespace app.interactions
	context app.interactions { }
	
45. We need to add a matching entity definition for the Calculation View. This means redefining all the column names and data types / lengths. 
    Doing so manually would be error prone, but the hana-cli has a utility that will help. Open a terminal and change to the db folder with the 
	command cd db. Now issue the command:
	 [hana-cli inspectView -v V_INTERACTION -o cds]  // in db folder
	 
46. Copy this block from the terminal and paste it into the schema.cds file at the end outside the context block.

47. CDS does have an annotation called @cds.persistence.exists. This annotation allows you to re-define an existing DB object and CDS won’t attempt
    to create or alter it. It will just assume it already exists in the matching state.There is also the annotation @cds.persistence.calcview. 
	This will further tell the Cloud Application Programming Model that this target entity is also a Calculation View.
	
	import the schema entity in cds file
	
48. cds build and cds watch --profile hybrid

Procedure 4:
===============

 Create HANA Stored Procedure and Expose as CAP Service Function (SAP HANA Cloud)
====================================================================
49. In the /db/src folder create a new database artifact named sleep of type hdbprocedure
      1.specify where you want to create the new artifact: /db/src
      2.choose the database verson: HANA Cloud
	  3. choose the artifact type: procedure
	  4. specify the artifact name: sleep
	  
	  click on create
	  
50. This is a very simple SAP HANA Stored Procedure that calls the built-in SYNC library to put processing to 
    sleep 
    for 10 seconds. It’s a nice tool to be able to test the impact of long running queries 
	without actually putting unnecessary load on the system.
   
    in sleep.hdbprocedure:  
	SQL: PROCEDURE "sleep" ( )
		   LANGUAGE SQLSCRIPT
		   SQL SECURITY INVOKER
		   READS SQL DATA AS
		BEGIN USING SQLSCRIPT_SYNC as SyncLib;

		call SyncLib:SLEEP_SECONDS(10);

		END
		
51. Deploy the to the database again using the SAP HANA Projects view and Check the 
    deployment log to make sure everything was successfully created in the database.

52. Open the HDI Container in the Database Explorer

53. This new Procedure is there now and can be tested. and right click on that procedure and 
   click: Generate Call Statement

54. There isn’t much output from the execution, but the 10 second wait makes testing quite easy.
 and click on run button 
    see the client capsule time in messages after run i.e; 10.00s
	
Add procedure to CAP service:
----------------------------
55. Now we want to add this Procedure to the CAP service as a function. Edit /srv/interaction_srv.cds.

Add: function sleep() returns Boolean; to the service definition.

This will expose an OData Function as part of the service interface.

56. Create interaction_srv.js file in srv folder 
    In interaction_srv.js we will implement the call to the Stored Procedure. This logic will implement the exit
	handler for this function which in turn uses the standard hdb Node.js module to call the Stored Procedure
	from SAP HANA Cloud. Save the file.
	
57. Paste the code
     const cds = require('@sap/cds')
		module.exports = cds.service.impl(function () {
			this.on('sleep', async () => {
			try {
				let dbQuery = ' Call "sleep"( )'
				let result = await cds.run(dbQuery, { })
				console.log(result)
				return true
			} catch (error) {
				console.error(error)
				return false
			}
			})
		})

58. cds build and deploy and cds watch or cds watch --profile hybrid

59. The CAP preview UI doesn’t list functions or actions, however. 
    Manually add /project/sleep() to the end of the URL. If it works correctly it should take 10 seconds to 
	respond since the procedure is running a sleep operation for that long. which is running on port 5000